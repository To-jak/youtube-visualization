{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jean/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import all necessary packages\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ro6eob0LrCY</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Malika LePen : Femme de Gauche - Trailer</td>\n",
       "      <td>Le Raptor Dissident</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T17:32:55.000Z</td>\n",
       "      <td>Raptor\"|\"Dissident\"|\"Expliquez\"|\"moi\"|\"cette\"|...</td>\n",
       "      <td>212702</td>\n",
       "      <td>29282</td>\n",
       "      <td>1108</td>\n",
       "      <td>3817</td>\n",
       "      <td>https://i.ytimg.com/vi/Ro6eob0LrCY/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Dimanche.\\n18h30.\\nSoyez présents pour la vidé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yo84eqYwP98</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>LA PIRE PARTIE ft Le Rire Jaune, Pierre Croce,...</td>\n",
       "      <td>Le Labo</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-12T15:00:02.000Z</td>\n",
       "      <td>[none]</td>\n",
       "      <td>432721</td>\n",
       "      <td>14053</td>\n",
       "      <td>576</td>\n",
       "      <td>1161</td>\n",
       "      <td>https://i.ytimg.com/vi/Yo84eqYwP98/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Le jeu de société: https://goo.gl/hhG1Ta\\n\\nGa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ceqntSXE-10</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>DESSINS ANIMÉS FRANÇAIS VS RUSSES 2 - Daniil...</td>\n",
       "      <td>Daniil le Russe</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-13T17:00:38.000Z</td>\n",
       "      <td>cartoon\"|\"pokémon\"|\"école\"|\"ours\"|\"мультфильм</td>\n",
       "      <td>482153</td>\n",
       "      <td>76203</td>\n",
       "      <td>477</td>\n",
       "      <td>9580</td>\n",
       "      <td>https://i.ytimg.com/vi/ceqntSXE-10/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Une nouvelle dose de dessins animés français e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WuTFI5qftCE</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>PAPY GRENIER - METAL GEAR SOLID</td>\n",
       "      <td>Joueur Du Grenier</td>\n",
       "      <td>20</td>\n",
       "      <td>2017-11-12T17:00:02.000Z</td>\n",
       "      <td>Papy grenier\"|\"Metal Gear Solid\"|\"PS1\"|\"Tirage...</td>\n",
       "      <td>925222</td>\n",
       "      <td>85016</td>\n",
       "      <td>550</td>\n",
       "      <td>4303</td>\n",
       "      <td>https://i.ytimg.com/vi/WuTFI5qftCE/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Nouvel ,épisode de Papy Grenier ! Ce mois-ci o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ee6OFs8TdEg</th>\n",
       "      <td>17.14.11</td>\n",
       "      <td>QUI SAUTERA LE PLUS HAUT ? (VÉLO SKATE ROLLER ...</td>\n",
       "      <td>Aurelien Fontenoy</td>\n",
       "      <td>17</td>\n",
       "      <td>2017-11-13T16:30:03.000Z</td>\n",
       "      <td>vélo\"|\"vtt\"|\"bmx\"|\"freestyle\"|\"bike\"|\"mtb\"|\"di...</td>\n",
       "      <td>141695</td>\n",
       "      <td>8091</td>\n",
       "      <td>72</td>\n",
       "      <td>481</td>\n",
       "      <td>https://i.ytimg.com/vi/ee6OFs8TdEg/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sauts à plus de 4 mètres de haut dans un tramp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            trending_date                                              title  \\\n",
       "video_id                                                                       \n",
       "Ro6eob0LrCY      17.14.11           Malika LePen : Femme de Gauche - Trailer   \n",
       "Yo84eqYwP98      17.14.11  LA PIRE PARTIE ft Le Rire Jaune, Pierre Croce,...   \n",
       "ceqntSXE-10      17.14.11  DESSINS ANIMÉS FRANÇAIS VS RUSSES 2 - Daniil...   \n",
       "WuTFI5qftCE      17.14.11                    PAPY GRENIER - METAL GEAR SOLID   \n",
       "ee6OFs8TdEg      17.14.11  QUI SAUTERA LE PLUS HAUT ? (VÉLO SKATE ROLLER ...   \n",
       "\n",
       "                   channel_title  category_id              publish_time  \\\n",
       "video_id                                                                  \n",
       "Ro6eob0LrCY  Le Raptor Dissident           24  2017-11-13T17:32:55.000Z   \n",
       "Yo84eqYwP98              Le Labo           24  2017-11-12T15:00:02.000Z   \n",
       "ceqntSXE-10      Daniil le Russe           23  2017-11-13T17:00:38.000Z   \n",
       "WuTFI5qftCE    Joueur Du Grenier           20  2017-11-12T17:00:02.000Z   \n",
       "ee6OFs8TdEg    Aurelien Fontenoy           17  2017-11-13T16:30:03.000Z   \n",
       "\n",
       "                                                          tags   views  likes  \\\n",
       "video_id                                                                        \n",
       "Ro6eob0LrCY  Raptor\"|\"Dissident\"|\"Expliquez\"|\"moi\"|\"cette\"|...  212702  29282   \n",
       "Yo84eqYwP98                                             [none]  432721  14053   \n",
       "ceqntSXE-10      cartoon\"|\"pokémon\"|\"école\"|\"ours\"|\"мультфильм  482153  76203   \n",
       "WuTFI5qftCE  Papy grenier\"|\"Metal Gear Solid\"|\"PS1\"|\"Tirage...  925222  85016   \n",
       "ee6OFs8TdEg  vélo\"|\"vtt\"|\"bmx\"|\"freestyle\"|\"bike\"|\"mtb\"|\"di...  141695   8091   \n",
       "\n",
       "             dislikes  comment_count  \\\n",
       "video_id                               \n",
       "Ro6eob0LrCY      1108           3817   \n",
       "Yo84eqYwP98       576           1161   \n",
       "ceqntSXE-10       477           9580   \n",
       "WuTFI5qftCE       550           4303   \n",
       "ee6OFs8TdEg        72            481   \n",
       "\n",
       "                                             thumbnail_link  \\\n",
       "video_id                                                      \n",
       "Ro6eob0LrCY  https://i.ytimg.com/vi/Ro6eob0LrCY/default.jpg   \n",
       "Yo84eqYwP98  https://i.ytimg.com/vi/Yo84eqYwP98/default.jpg   \n",
       "ceqntSXE-10  https://i.ytimg.com/vi/ceqntSXE-10/default.jpg   \n",
       "WuTFI5qftCE  https://i.ytimg.com/vi/WuTFI5qftCE/default.jpg   \n",
       "ee6OFs8TdEg  https://i.ytimg.com/vi/ee6OFs8TdEg/default.jpg   \n",
       "\n",
       "             comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "video_id                                                                   \n",
       "Ro6eob0LrCY              False             False                   False   \n",
       "Yo84eqYwP98              False             False                   False   \n",
       "ceqntSXE-10              False             False                   False   \n",
       "WuTFI5qftCE              False             False                   False   \n",
       "ee6OFs8TdEg              False             False                   False   \n",
       "\n",
       "                                                   description  \n",
       "video_id                                                        \n",
       "Ro6eob0LrCY  Dimanche.\\n18h30.\\nSoyez présents pour la vidé...  \n",
       "Yo84eqYwP98  Le jeu de société: https://goo.gl/hhG1Ta\\n\\nGa...  \n",
       "ceqntSXE-10  Une nouvelle dose de dessins animés français e...  \n",
       "WuTFI5qftCE  Nouvel ,épisode de Papy Grenier ! Ce mois-ci o...  \n",
       "ee6OFs8TdEg  Sauts à plus de 4 mètres de haut dans un tramp...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "\n",
    "my_df = pd.read_csv('/home/jean/4549_466349_bundle_archive/FRvideos.csv', index_col='video_id')\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laoading stopwords to remove it from the text\n",
    "\n",
    "en_stopwords = list(stopwords.words('english'))\n",
    "fr_stopwords = list(stopwords.words('french'))   \n",
    "en_stopwords.extend(fr_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jean/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Filtering tags with regex to tokenized it\n",
    "\n",
    "my_df['tags'] = my_df['tags'].str.lower()\n",
    "\n",
    "\n",
    "for i in range (len(my_df['tags'])):\n",
    "    tw = re.sub('[^A-Za-zçéè]+', ' ', my_df.iloc[i]['tags'])\n",
    "    word_tokens = word_tokenize(tw)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in en_stopwords]\n",
    "    without_single_chr = [word for word in filtered_sentence if len(word) > 2]\n",
    "    my_df['tags'][i] = str([word for word in without_single_chr if not word.isdigit()])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping tags that were empty before ([none]) and tags that are empty after ([]) filtering\n",
    "\n",
    "my_df = my_df[my_df.tags != \"['none']\"]\n",
    "my_df = my_df[my_df.tags != \"[]\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>publish_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>k_KXgkEZGtI</th>\n",
       "      <td>2017-11-12</td>\n",
       "      <td>11:42:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tgjTYiowYZk</th>\n",
       "      <td>2017-11-13</td>\n",
       "      <td>16:59:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jKfNUQsYMYI</th>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>17:00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1cr9mQh_IlA</th>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>19:06:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7Cj6P13MUNU</th>\n",
       "      <td>2017-11-13</td>\n",
       "      <td>08:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            publish_date publish_time\n",
       "video_id                             \n",
       "k_KXgkEZGtI   2017-11-12     11:42:39\n",
       "tgjTYiowYZk   2017-11-13     16:59:03\n",
       "jKfNUQsYMYI   2017-11-11     17:00:05\n",
       "1cr9mQh_IlA   2017-11-11     19:06:46\n",
       "7Cj6P13MUNU   2017-11-13     08:00:00"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reformate date\n",
    "\n",
    "my_df['trending_date'] = pd.to_datetime(my_df['trending_date'],errors='coerce', format='%y.%d.%m')\n",
    "my_df['publish_time'] = pd.to_datetime(my_df['publish_time'], errors='coerce', format='%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "\n",
    "my_df = my_df[my_df['trending_date'].notnull()]\n",
    "my_df = my_df[my_df['publish_time'].notnull()]\n",
    "\n",
    "my_df = my_df.dropna(how='any',inplace=False, axis = 0)\n",
    "\n",
    "my_df.insert(4, 'publish_date', my_df['publish_time'].dt.date)\n",
    "my_df['publish_time'] = my_df['publish_time'].dt.time\n",
    "\n",
    "my_df_full = my_df.reset_index().sort_values('trending_date').set_index('video_id')\n",
    "my_df = my_df.reset_index().sort_values('trending_date').drop_duplicates('video_id',keep='last').set_index('video_id')\n",
    "my_df[['publish_date','publish_time']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sports', 'Music', 'Science & Technology', 'Entertainment',\n",
       "       'Howto & Style', 'Gaming', 'People & Blogs', 'News & Politics',\n",
       "       'Comedy', 'Film & Animation', 'Autos & Vehicles', 'Education',\n",
       "       'Travel & Events', 'Shows', 'Pets & Animals', nan, 'Movies',\n",
       "       'Trailers'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Associating category_id with the correct category name with the .json file\n",
    "\n",
    "my_df['category_id'] = my_df['category_id'].astype(str)\n",
    "my_df_full['category_id'] = my_df['category_id'].astype(str)\n",
    "\n",
    "category_id = {}\n",
    "\n",
    "with open('/home/jean/4549_466349_bundle_archive/FR_category_id.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    for category in data['items']:\n",
    "        category_id[category['id']] = category['snippet']['title']\n",
    "\n",
    "my_df.insert(4, 'category', my_df['category_id'].map(category_id))\n",
    "my_df_full.insert(4, 'category', my_df_full['category_id'].map(category_id))\n",
    "category_list = my_df['category'].unique()\n",
    "category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_to_trend</th>\n",
       "      <th>trend_duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>video_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>k_KXgkEZGtI</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PKBug0-mzGs</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vIc_p28woYA</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qebEL68KsdY</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OoREgT676E0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             publish_to_trend  trend_duration\n",
       "video_id                                     \n",
       "k_KXgkEZGtI                 2               1\n",
       "PKBug0-mzGs                 1               1\n",
       "vIc_p28woYA                 1               1\n",
       "qebEL68KsdY                 1               1\n",
       "OoREgT676E0                 1               1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new data values 'publish_to_train' and 'trend_duration' to make dataframe more explicit \n",
    "\n",
    "publish_to_trend = {}\n",
    "my_df_first = my_df_full.reset_index().drop_duplicates('video_id',keep ='first').set_index('video_id')\n",
    "diff_first = (my_df_first['trending_date']).astype('datetime64[ns]')-my_df_first['publish_date'].astype('datetime64[ns]')\n",
    "\n",
    "diff_first = diff_first.reset_index()\n",
    "diff_first.columns = ['video_id','publish_to_trend']\n",
    "\n",
    "for i, row in diff_first.iterrows():\n",
    "    publish_to_trend[row['video_id']] = row['publish_to_trend'].days\n",
    "\n",
    "my_df_last = my_df\n",
    "diff_last = my_df['trending_date'].astype('datetime64[ns]')-my_df['publish_date'].astype('datetime64[ns]')\n",
    "diff_last = diff_last.reset_index()\n",
    "diff_last.columns = ['video_id','publish_to_trend_last']\n",
    "my_df = my_df.reset_index()\n",
    "my_df.insert(4,'publish_to_trend_last', diff_last['publish_to_trend_last'].astype('timedelta64[D]').astype(int))\n",
    "my_df.insert(4, 'publish_to_trend', my_df['video_id'].map(publish_to_trend))\n",
    "my_df.insert(4, 'trend_duration', 0)\n",
    "my_df['trend_duration'] = (my_df['publish_to_trend_last']-my_df['publish_to_trend'])+1\n",
    "my_df = my_df[my_df.video_id != 'FeRi86DcfyA']\n",
    "my_df.set_index('video_id')[['publish_to_trend','trend_duration']].sort_values('trend_duration',ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping empty row\n",
    "\n",
    "my_df = my_df.dropna(how='any',inplace=False, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the trnasformation\n",
    "\n",
    "my_df.to_csv(r'/home/jean/clean_data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
